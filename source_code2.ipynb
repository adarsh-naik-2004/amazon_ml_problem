{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q68TCIZ9uE0k",
        "outputId": "16126220-ac01-4b2c-86f3-33dd932ed4f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "OBJH8E-PvVTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/student_resource 3/src')"
      ],
      "metadata": {
        "id": "VYXbcwQlzMDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/student_resource 3/dataset')"
      ],
      "metadata": {
        "id": "a6DryuH7zhiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_FOLDER = '/content/drive/MyDrive/student_resource 3/dataset'\n",
        "train = pd.read_csv(os.path.join(DATASET_FOLDER, 'train.csv'))\n",
        "test = pd.read_csv(os.path.join(DATASET_FOLDER, 'test.csv'))\n",
        "sample_test = pd.read_csv(os.path.join(DATASET_FOLDER, 'sample_test.csv'))\n",
        "sample_test_out = pd.read_csv(os.path.join(DATASET_FOLDER, 'sample_test_out.csv'))"
      ],
      "metadata": {
        "id": "Qyw6JcY_vdoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.rmtree('/content/drive/MyDrive/student_resource 3/dataset/images')"
      ],
      "metadata": {
        "id": "FxoLpoJlEDqn"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import urllib.request\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 1. Load and Sample the Dataset\n",
        "data = pd.read_csv('/content/drive/MyDrive/student_resource 3/dataset/train.csv')  # Replace with actual dataset\n",
        "data_sampled = data.sample(frac=0.01, random_state=42)  # Taking 1% of the data\n",
        "\n",
        "# 2. Download the Images\n",
        "if not os.path.exists('/content/drive/MyDrive/student_resource 3/dataset/images'):\n",
        "    os.makedirs('/content/drive/MyDrive/student_resource 3/dataset/images')\n",
        "\n",
        "def download_image(image_url, save_path):\n",
        "    try:\n",
        "        urllib.request.urlretrieve(image_url, save_path)\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to download {image_url}: {str(e)}\")\n",
        "\n",
        "for index, row in data_sampled.iterrows():\n",
        "    image_url = row['image_link']\n",
        "    save_path = os.path.join('images', f\"{row['group_id']}.jpg\")\n",
        "    download_image(image_url, save_path)\n",
        "\n",
        "# 3. Preprocessing and Dataset Class for PyTorch\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, dataframe, img_dir, transform=None):\n",
        "        self.dataframe = dataframe\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.img_dir, f\"{self.dataframe.iloc[idx]['group_id']}.jpg\")\n",
        "        image = Image.open(img_name).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        entity_name = self.dataframe.iloc[idx]['entity_name']\n",
        "        entity_value = self.dataframe.iloc[idx]['entity_value']\n",
        "\n",
        "        # Converting entity name to a numerical value if needed (use one-hot encoding or simple mapping)\n",
        "        entity_value = self._convert_to_numeric(entity_value)  # This needs to be implemented based on your target\n",
        "\n",
        "        return image, entity_name, entity_value\n",
        "\n",
        "    def _convert_to_numeric(self, value):\n",
        "        # Conversion logic: For example, you can convert weights/volumes to grams/milliliters\n",
        "        try:\n",
        "            if 'gram' in value:\n",
        "                return float(value.split()[0])  # Simple example, you might need more complex parsing\n",
        "            elif 'kilogram' in value:\n",
        "                return float(value.split()[0]) * 1000\n",
        "            elif 'milliliter' in value:\n",
        "                return float(value.split()[0]) *4000\n",
        "            elif 'liter' in value:\n",
        "                return float(value.split()[0]) * 10\n",
        "            elif 'gallob' in value:\n",
        "                return float(value.split()[0]) * 3.785\n",
        "            elif 'watt' in value:\n",
        "                return float(value.split()[0]) * 7000\n",
        "            elif 'pound' in value:\n",
        "                return float(value.split()[0]) * 453.592\n",
        "            elif 'ounce' in value:\n",
        "                return float(value.split()[0]) * 28.3495\n",
        "            elif 'volt' in value:\n",
        "                return float(value.split()[0]) * 8000\n",
        "            elif 'fluid ounce' in value:\n",
        "                return float(value.split()[0]) * 2900.5735\n",
        "            elif 'ton' in value:\n",
        "                return float(value.split()[0]) * 100000\n",
        "            elif 'inch' in value:\n",
        "                return float(value.split()[0]) * 254\n",
        "            elif 'milligram' in value:\n",
        "                return float(value.split()[0]) * 20000\n",
        "            elif 'microgram' in value:\n",
        "                return float(value.split()[0]) *30000\n",
        "            # Add more conversions for other units\n",
        "            else:\n",
        "                return 0.0\n",
        "        except:\n",
        "            return 0.0\n",
        "\n",
        "# 4. Define Transforms and Load Dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "dataset = ImageDataset(data_sampled, img_dir='images', transform=transform)\n",
        "train_data, test_data = train_test_split(dataset, test_size=0.2, random_state=42)\n",
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
        "\n",
        "# 5. Define the Model (CNN + Fully Connected for entity_name)\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self, num_classes=1):  # We're predicting a single numeric value (entity_value)\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.cnn = models.resnet18(pretrained=True)\n",
        "        self.cnn.fc = nn.Linear(self.cnn.fc.in_features, 512)  # Adjust final layer for feature extraction\n",
        "\n",
        "        self.fc_entity_name = nn.Linear(512, 256)  # Optional: If you want to use entity name in prediction\n",
        "        self.fc_final = nn.Linear(512, num_classes)\n",
        "\n",
        "    def forward(self, image, entity_name):\n",
        "        image_features = self.cnn(image)  # CNN image features\n",
        "\n",
        "        # Optional: If entity_name is numeric, you can concatenate it with image_features\n",
        "        # entity_features = self.fc_entity_name(entity_name)\n",
        "        # combined_features = torch.cat((image_features, entity_features), dim=1)\n",
        "\n",
        "        output = self.fc_final(image_features)\n",
        "        return output\n",
        "\n",
        "# 6. Initialize Model, Loss, and Optimizer\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CNNModel().to(device)\n",
        "criterion = nn.MSELoss()  # Since we're predicting a continuous value (entity_value)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# 7. Training Loop\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    images = images.float()\n",
        "    entity_values = entity_values.float()\n",
        "    for images, entity_names, entity_values in train_loader:\n",
        "        images, entity_values = images.to(device), entity_values.to(device).float()  # Convert target to float\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images, entity_names)\n",
        "        loss = criterion(outputs, entity_values.unsqueeze(1))  # Ensure correct shape for MSE\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader)}\")\n",
        "\n",
        "# 8. Testing Loop\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    total_loss = 0.0\n",
        "    for images, entity_names, entity_values in test_loader:\n",
        "        images, entity_values = images.to(device), entity_values.to(device).float()  # Convert target to float\n",
        "\n",
        "        outputs = model(images, entity_names)\n",
        "        loss = criterion(outputs, entity_values.unsqueeze(1))\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Test Loss: {total_loss/len(test_loader)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6XlwWygK_lL",
        "outputId": "24248053-049f-4858-d303-69dcb4401211"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 1562505.8695803555\n",
            "Epoch [2/10], Loss: 1551852.5506036931\n",
            "Epoch [3/10], Loss: 1557471.4860617898\n",
            "Epoch [4/10], Loss: 1557566.7972227153\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Myr5ok9xkto4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}